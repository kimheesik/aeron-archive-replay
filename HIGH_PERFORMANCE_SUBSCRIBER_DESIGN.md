# High-Performance Subscriber Architecture Design

**ë‚ ì§œ**: 2025-11-18
**ëª©ì **: Zero-copy ê¸°ë°˜ ê³ ì„±ëŠ¥ ë©”ì‹œì§€ ì²˜ë¦¬ ì•„í‚¤í…ì²˜ ì„¤ê³„
**ìš”êµ¬ì‚¬í•­**: Subscriber Thread + Worker Thread ë¶„ë¦¬, Zero-copy Queue, ëª¨ë‹ˆí„°ë§ í†µí•©

---

## 1. ì•„í‚¤í…ì²˜ ê°œìš”

### 1.1 í˜„ì¬ ì•„í‚¤í…ì²˜ (Single Thread)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Main Thread (Subscriber)         â”‚
â”‚                                         â”‚
â”‚  Aeron Reception                        â”‚
â”‚       â†“                                 â”‚
â”‚  handleMessage()                        â”‚
â”‚       â†“                                 â”‚
â”‚  Parse + Validate                       â”‚
â”‚       â†“                                 â”‚
â”‚  Latency Measurement                    â”‚
â”‚       â†“                                 â”‚
â”‚  Message Callback (monitoring)          â”‚
â”‚       â†“                                 â”‚
â”‚  [Business Logic would go here]         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ì œì•½ì‚¬í•­:
- ëª¨ë“  ì²˜ë¦¬ê°€ Aeron polling ë£¨í”„ì—ì„œ ë°œìƒ
- ë¬´ê±°ìš´ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì‹œ ë©”ì‹œì§€ ìˆ˜ì‹  ì§€ì—°
- Aeronì˜ fragment handlerê°€ blockingë˜ë©´ ì„±ëŠ¥ ì €í•˜
```

### 1.2 ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ (Multi Thread + Zero-copy)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Subscriber Thread       â”‚          â”‚  Worker Thread(s)        â”‚
â”‚  (Aeron Reception Only)  â”‚          â”‚  (Message Processing)    â”‚
â”‚                          â”‚          â”‚                          â”‚
â”‚  Aeron::poll()           â”‚          â”‚                          â”‚
â”‚      â†“                   â”‚          â”‚  while(running) {        â”‚
â”‚  handleMessage()         â”‚          â”‚    Buffer* buf =         â”‚
â”‚      â†“                   â”‚          â”‚      queue.dequeue()     â”‚
â”‚  recv_timestamp          â”‚          â”‚                          â”‚
â”‚      â†“                   â”‚          â”‚    Parse message         â”‚
â”‚  Get Buffer from Pool    â”‚          â”‚    Validate              â”‚
â”‚      â†“                   â”‚   Queue  â”‚    Business Logic        â”‚
â”‚  Zero-copy to Buffer â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚    Monitoring            â”‚
â”‚      â†“                   â”‚ (Pointer)â”‚                          â”‚
â”‚  Enqueue(buffer*)        â”‚          â”‚    Return buf to pool    â”‚
â”‚      â†“                   â”‚          â”‚  }                       â”‚
â”‚  Continue polling        â”‚          â”‚                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                                      â†“
    < 1 Î¼s/msg                              Variable time
    (No blocking)                           (Can be slow)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Monitoring Thread       â”‚
â”‚  (Statistics)            â”‚
â”‚                          â”‚
â”‚  Read from Stats Queue   â”‚
â”‚  Print every 100 msgs    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**í•µì‹¬ ê°œì„ ì **:
1. **Subscriber Thread**: Aeron ìˆ˜ì‹ ë§Œ ë‹´ë‹¹ â†’ í•­ìƒ ë¹ ë¥´ê²Œ poll
2. **Worker Thread**: ë¬´ê±°ìš´ ì²˜ë¦¬ ë‹´ë‹¹ â†’ Aeron ìˆ˜ì‹ ê³¼ ë…ë¦½ì 
3. **Zero-copy Queue**: Buffer í¬ì¸í„°ë§Œ ì „ë‹¬ â†’ ë°ì´í„° ë³µì‚¬ ì—†ìŒ
4. **Buffer Pool**: ì‚¬ì „ í• ë‹¹ â†’ ë™ì  í• ë‹¹ ì˜¤ë²„í—¤ë“œ ì œê±°

---

## 2. Zero-Copy Buffer Pool ì„¤ê³„

### 2.1 Buffer êµ¬ì¡°

```cpp
#pragma pack(push, 1)
struct MessageBuffer {
    // Header (64 bytes, cache-line aligned)
    struct {
        uint8_t  magic[4];           // "SEKR"
        uint16_t version;            // Protocol version
        uint16_t message_type;       // Message type
        uint64_t sequence_number;    // Sequence for dedup

        uint64_t event_time_ns;      // Event timestamp
        uint64_t publish_time_ns;    // Publish timestamp
        uint64_t recv_time_ns;       // Receive timestamp (filled by subscriber)

        uint32_t message_length;     // Total length
        uint16_t publisher_id;       // Publisher ID
        uint8_t  priority;           // Priority
        uint8_t  flags;              // Flags
        uint64_t session_id;         // Session ID

        uint32_t checksum;           // CRC32
        uint32_t reserved;           // Future use
    } header;

    // Payload (variable, up to MAX_PAYLOAD_SIZE)
    uint8_t payload[MAX_PAYLOAD_SIZE];  // e.g., 4KB

    // Metadata for pool management (not part of wire format)
    std::atomic<bool> in_use{false};
    uint32_t actual_payload_length;
};
#pragma pack(pop)

// Recommended sizes:
// - MAX_PAYLOAD_SIZE: 4KB (fits most messages)
// - Total buffer: ~4.1KB per buffer
// - Pool size: 1024 buffers = ~4.2MB memory
```

### 2.2 Lock-free Buffer Pool

```cpp
/**
 * Lock-free Buffer Pool
 * - Pre-allocated buffers (avoid malloc/free)
 * - Lock-free allocation/deallocation
 * - O(1) operations
 */
template<size_t PoolSize>
class BufferPool {
public:
    BufferPool() {
        // Initialize free list
        for (size_t i = 0; i < PoolSize; i++) {
            free_list_[i] = &buffers_[i];
        }
        free_count_.store(PoolSize, std::memory_order_release);
    }

    // Allocate buffer (~50-100ns)
    MessageBuffer* allocate() noexcept {
        size_t count = free_count_.load(std::memory_order_acquire);

        while (count > 0) {
            if (free_count_.compare_exchange_weak(
                    count, count - 1,
                    std::memory_order_release,
                    std::memory_order_relaxed)) {

                MessageBuffer* buf = free_list_[count - 1];
                buf->in_use.store(true, std::memory_order_release);
                return buf;
            }
        }

        return nullptr;  // Pool exhausted
    }

    // Deallocate buffer (~50-100ns)
    void deallocate(MessageBuffer* buf) noexcept {
        buf->in_use.store(false, std::memory_order_release);

        size_t count = free_count_.load(std::memory_order_acquire);
        while (count < PoolSize) {
            if (free_count_.compare_exchange_weak(
                    count, count + 1,
                    std::memory_order_release,
                    std::memory_order_relaxed)) {

                free_list_[count] = buf;
                return;
            }
        }
    }

    size_t available() const noexcept {
        return free_count_.load(std::memory_order_acquire);
    }

private:
    alignas(64) MessageBuffer buffers_[PoolSize];
    alignas(64) MessageBuffer* free_list_[PoolSize];
    alignas(64) std::atomic<size_t> free_count_;
};

using MessageBufferPool = BufferPool<1024>;  // 1024 buffers = ~4.2MB
```

**ì„±ëŠ¥ íŠ¹ì„±**:
- **Allocate**: ~50-100ns (CAS loop)
- **Deallocate**: ~50-100ns (CAS loop)
- **Memory**: 4.2MB (1024 buffers Ã— 4.1KB)
- **Pool exhaustion**: Return nullptr, caller handles backpressure

### 2.3 Zero-Copy Queue

```cpp
/**
 * Zero-Copy Message Queue
 * - Passes buffer pointers, not data
 * - Lock-free SPSC (Single Producer Single Consumer)
 * - Power-of-2 size for fast modulo
 */
template<size_t Size>
class MessageQueue {
    static_assert((Size & (Size - 1)) == 0, "Size must be power of 2");

public:
    // Enqueue buffer pointer (~50ns)
    bool enqueue(MessageBuffer* buf) noexcept {
        const size_t current_tail = tail_.load(std::memory_order_relaxed);
        const size_t next_tail = (current_tail + 1) & (Size - 1);

        if (next_tail == head_.load(std::memory_order_acquire)) {
            return false;  // Queue full
        }

        buffer_[current_tail] = buf;
        tail_.store(next_tail, std::memory_order_release);
        return true;
    }

    // Dequeue buffer pointer (~50ns)
    bool dequeue(MessageBuffer*& buf) noexcept {
        const size_t current_head = head_.load(std::memory_order_relaxed);

        if (current_head == tail_.load(std::memory_order_acquire)) {
            return false;  // Queue empty
        }

        buf = buffer_[current_head];
        head_.store((current_head + 1) & (Size - 1), std::memory_order_release);
        return true;
    }

    size_t size() const noexcept {
        const size_t h = head_.load(std::memory_order_acquire);
        const size_t t = tail_.load(std::memory_order_acquire);
        return (t - h) & (Size - 1);
    }

private:
    alignas(64) std::atomic<size_t> head_{0};
    alignas(64) std::atomic<size_t> tail_{0};
    alignas(64) MessageBuffer* buffer_[Size];
};

using MessageBufferQueue = MessageQueue<4096>;  // 4K slots
```

**ì„±ëŠ¥ íŠ¹ì„±**:
- **Enqueue/Dequeue**: ~50ns (í¬ì¸í„° ë³µì‚¬ë§Œ)
- **Memory**: 32KB (4096 slots Ã— 8 bytes)
- **Capacity**: 4095 messages in-flight
- **Zero-copy**: ë°ì´í„° ë³µì‚¬ ì—†ìŒ, í¬ì¸í„°ë§Œ ì „ë‹¬

---

## 3. Thread ì„¤ê³„

### 3.1 Subscriber Thread (High Priority)

```cpp
class AeronSubscriber {
public:
    void runSubscriberThread() {
        // Set high priority
        setThreadPriority(THREAD_PRIORITY_HIGH);

        // Optional: Pin to specific CPU core
        // setThreadAffinity(0);  // Core 0

        while (running_.load(std::memory_order_acquire)) {
            // Poll Aeron (non-blocking)
            int fragments = subscription_->poll(
                [this](auto& buffer, auto offset, auto length, auto& header) {
                    this->handleMessageFastPath(buffer, offset, length, header);
                },
                FRAGMENT_LIMIT  // e.g., 10
            );

            if (fragments == 0) {
                // No messages, yield CPU briefly
                std::this_thread::yield();
            }
        }
    }

private:
    void handleMessageFastPath(
        AtomicBuffer& buffer,
        util::index_t offset,
        util::index_t length,
        Header& header) {

        // 1. Record receive timestamp IMMEDIATELY
        int64_t recv_timestamp = getCurrentTimeNanos();

        // 2. Get buffer from pool (~100ns)
        MessageBuffer* msg_buf = buffer_pool_.allocate();

        if (!msg_buf) {
            // Pool exhausted - drop message or handle backpressure
            dropped_count_.fetch_add(1, std::memory_order_relaxed);
            return;
        }

        // 3. Zero-copy: memcpy Aeron buffer to our buffer (~500ns for 4KB)
        //    This is unavoidable - Aeron's buffer is ephemeral
        std::memcpy(&msg_buf->header, buffer.buffer() + offset,
                    std::min(length, sizeof(MessageBuffer)));

        msg_buf->actual_payload_length = length - sizeof(msg_buf->header);
        msg_buf->header.recv_time_ns = recv_timestamp;

        // 4. Enqueue to worker thread (~50ns)
        if (!message_queue_.enqueue(msg_buf)) {
            // Queue full - return buffer to pool
            buffer_pool_.deallocate(msg_buf);
            queue_full_count_.fetch_add(1, std::memory_order_relaxed);
            return;
        }

        // Total time: ~100 + 500 + 50 = ~650ns
        // Compare to current: ~337ns baseline + variable processing
        // Overhead: ~300ns, but enables non-blocking reception
    }

    MessageBufferPool buffer_pool_;
    MessageBufferQueue message_queue_;
    std::atomic<uint64_t> dropped_count_{0};
    std::atomic<uint64_t> queue_full_count_{0};
};
```

**ì±…ì„**:
- Aeron ë©”ì‹œì§€ ìˆ˜ì‹ ë§Œ ë‹´ë‹¹
- ìµœì†Œí•œì˜ ì²˜ë¦¬ (íƒ€ì„ìŠ¤íƒ¬í”„ + ë²„í¼ ë³µì‚¬ + enqueue)
- í•­ìƒ ë¹ ë¥´ê²Œ ì™„ë£Œ (~650ns ëª©í‘œ)
- Blocking ì‘ì—… ì ˆëŒ€ ê¸ˆì§€

**ì„±ëŠ¥ ëª©í‘œ**:
- Latency per message: < 1 Î¼s
- Throughput: > 1M msg/s (ì´ë¡ ì )

### 3.2 Worker Thread (Normal Priority)

```cpp
class MessageWorker {
public:
    void runWorkerThread(
        MessageBufferQueue& queue,
        MessageBufferPool& pool,
        MessageStatsQueue& stats_queue) {

        MessageBuffer* msg_buf = nullptr;
        uint64_t processed_count = 0;

        // Duplicate detection
        std::unordered_set<uint64_t> seen_sequences;
        seen_sequences.reserve(100000);  // Pre-allocate

        while (running_.load(std::memory_order_acquire)) {
            // 1. Dequeue message (~50ns)
            if (!queue.dequeue(msg_buf)) {
                // Queue empty - adaptive wait
                if (++empty_count_ < 100) {
                    std::this_thread::yield();
                } else {
                    std::this_thread::sleep_for(std::chrono::microseconds(10));
                }
                continue;
            }

            empty_count_ = 0;

            // 2. Validate message (~200ns)
            if (!validateMessage(msg_buf)) {
                pool.deallocate(msg_buf);
                continue;
            }

            // 3. Duplicate detection (~50ns with hash table)
            uint64_t seq = msg_buf->header.sequence_number;
            if (seen_sequences.count(seq) > 0) {
                // Duplicate detected
                duplicate_count_++;
                pool.deallocate(msg_buf);
                continue;
            }
            seen_sequences.insert(seq);

            // 4. Process message (variable time)
            processMessage(msg_buf);

            // 5. Send to monitoring (~50ns)
            sendToMonitoring(msg_buf, stats_queue);

            // 6. Return buffer to pool (~100ns)
            pool.deallocate(msg_buf);

            processed_count++;
        }
    }

private:
    bool validateMessage(MessageBuffer* buf) {
        // Check magic
        if (memcmp(buf->header.magic, "SEKR", 4) != 0) {
            return false;
        }

        // Verify checksum (if enabled)
        if (buf->header.flags & FLAG_CHECKSUM_ENABLED) {
            uint32_t calculated_crc = calculateCRC32(buf);
            if (calculated_crc != buf->header.checksum) {
                return false;
            }
        }

        return true;
    }

    void processMessage(MessageBuffer* buf) {
        switch (buf->header.message_type) {
            case MSG_ORDER_NEW:
                handleOrderNew(buf);
                break;
            case MSG_ORDER_EXECUTION:
                handleOrderExecution(buf);
                break;
            case MSG_ORDER_MODIFY:
                handleOrderModify(buf);
                break;
            case MSG_ORDER_CANCEL:
                handleOrderCancel(buf);
                break;
            case MSG_QUOTE_UPDATE:
                handleQuoteUpdate(buf);
                break;
            default:
                // Unknown message type
                break;
        }
    }

    void sendToMonitoring(MessageBuffer* buf, MessageStatsQueue& stats_queue) {
        MessageStats stats;
        stats.message_number = buf->header.sequence_number;
        stats.send_timestamp = buf->header.publish_time_ns;
        stats.recv_timestamp = buf->header.recv_time_ns;
        stats.position = 0;  // Not available in this architecture

        // Non-blocking enqueue
        stats_queue.enqueue(stats);
    }

    uint64_t empty_count_ = 0;
    uint64_t duplicate_count_ = 0;
};
```

**ì±…ì„**:
- ë©”ì‹œì§€ ê²€ì¦ (magic, checksum)
- ì¤‘ë³µ ì œê±° (sequence number ê¸°ë°˜)
- ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì²˜ë¦¬
- ëª¨ë‹ˆí„°ë§ ë°ì´í„° ì „ì†¡
- ë²„í¼ ë°˜í™˜

**ì„±ëŠ¥ íŠ¹ì„±**:
- ì²˜ë¦¬ ì‹œê°„: Variable (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì— ë”°ë¼)
- Subscriber threadì™€ ë…ë¦½ì 
- ëŠë ¤ë„ Aeron ìˆ˜ì‹ ì— ì˜í–¥ ì—†ìŒ

### 3.3 Monitoring Thread (Low Priority)

```cpp
// ê¸°ì¡´ ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œì™€ ë™ì¼
// MessageStatsQueueì—ì„œ dequeueí•˜ì—¬ 100ê±´ë§ˆë‹¤ ì¶œë ¥
// ë³€ê²½ ì—†ìŒ
```

---

## 4. ëª¨ë‹ˆí„°ë§ í†µí•© ì„¤ê³„

### 4.1 í˜„ì¬ ëª¨ë‹ˆí„°ë§ êµ¬ì¡°

```
Subscriber Thread:
  handleMessage()
    â†“
  message_callback_()  (if registered)
    â†“
  MessageStatsQueue.enqueue()

Monitoring Thread:
  MessageStatsQueue.dequeue()
    â†“
  Print stats every 100 messages
```

**ë¬¸ì œì **:
- Subscriber threadì—ì„œ ì§ì ‘ stats queueì— enqueue
- ìƒˆ ì•„í‚¤í…ì²˜ì—ì„œëŠ” Worker threadê°€ ë©”ì‹œì§€ ì²˜ë¦¬

### 4.2 ìƒˆë¡œìš´ ëª¨ë‹ˆí„°ë§ í†µí•©

**ì˜µì…˜ A: Worker Threadì—ì„œ ëª¨ë‹ˆí„°ë§** (ê¶Œì¥)

```
Subscriber Thread:          Worker Thread:               Monitoring Thread:
  Aeron::poll()              Process message              Dequeue stats
    â†“                           â†“                            â†“
  handleMessageFastPath()     Validate                    Print every 100
    â†“                           â†“
  MessageQueue.enqueue()      Duplicate check
                                â†“
                              Business logic
                                â†“
                              StatsQueue.enqueue() â†â”€â”€â”€â”€â”€â”€â”€â”€ Read from here
```

**ì¥ì **:
- ì¤‘ë³µ ì œê±° í›„ í†µê³„ (ì •í™•í•œ ë©”ì‹œì§€ ìˆ˜)
- ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì • ê°€ëŠ¥
- Subscriber thread ì˜¤ë²„í—¤ë“œ ìµœì†Œí™”

**ë‹¨ì **:
- ë„¤íŠ¸ì›Œí¬ ë ˆì´í„´ì‹œ + í ëŒ€ê¸° ì‹œê°„ í¬í•¨

**ì˜µì…˜ B: Subscriber Threadì—ì„œ ëª¨ë‹ˆí„°ë§**

```
Subscriber Thread:          Worker Thread:               Monitoring Thread:
  Aeron::poll()              Process message              Dequeue stats
    â†“                           â†“                            â†“
  handleMessageFastPath()     Validate                    Print every 100
    â†“                           â†“
  MessageQueue.enqueue()      Duplicate check
    â†“                           â†“
  StatsQueue.enqueue() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Read from here
```

**ì¥ì **:
- ìˆœìˆ˜ ë„¤íŠ¸ì›Œí¬ ë ˆì´í„´ì‹œ ì¸¡ì •
- ì¤‘ë³µ í¬í•¨ ìˆ˜ì‹  í†µê³„

**ë‹¨ì **:
- Subscriber thread ì˜¤ë²„í—¤ë“œ ì¦ê°€ (~50ns)
- ì¤‘ë³µ ë©”ì‹œì§€ í¬í•¨ëœ í†µê³„

**ì˜µì…˜ C: Dual Monitoring**

```
Subscriber Thread:          Worker Thread:               Monitoring Thread 1:
  Aeron::poll()              Process message              Network stats
    â†“                           â†“                            â†“
  handleMessageFastPath()     Validate                    Print network latency
    â†“                           â†“
  MessageQueue.enqueue()      Duplicate check            Monitoring Thread 2:
    â†“                           â†“                            â†“
  NetStatsQueue.enqueue() â”€â”€â†’ Business logic              Processing stats
                                â†“                            â†“
                              ProcStatsQueue.enqueue() â”€â”€â”€â†’ Print processing time
```

**ì¥ì **:
- ë„¤íŠ¸ì›Œí¬ ë ˆì´í„´ì‹œì™€ ì²˜ë¦¬ ì‹œê°„ ë¶„ë¦¬ ì¸¡ì •
- ìƒì„¸í•œ ì„±ëŠ¥ ë¶„ì„ ê°€ëŠ¥

**ë‹¨ì **:
- ë³µì¡ë„ ì¦ê°€
- 2ê°œ í†µê³„ í ê´€ë¦¬ í•„ìš”

### 4.3 ê¶Œì¥ êµ¬ì¡° (ì˜µì…˜ A)

```cpp
// Worker Threadì—ì„œ ëª¨ë‹ˆí„°ë§
void MessageWorker::processMessage(MessageBuffer* buf, MessageStatsQueue& stats_queue) {
    // ... validation, duplicate check ...

    // Business logic
    auto start_processing = getCurrentTimeNanos();
    handleBusinessLogic(buf);
    auto end_processing = getCurrentTimeNanos();

    // Send enhanced stats to monitoring
    MessageStats stats;
    stats.message_number = buf->header.sequence_number;
    stats.send_timestamp = buf->header.publish_time_ns;
    stats.recv_timestamp = buf->header.recv_time_ns;
    stats.processing_time_ns = end_processing - start_processing;

    stats_queue.enqueue(stats);
}
```

**í†µê³„ ì¶œë ¥ ì˜ˆì‹œ**:
```
========================================
ğŸ“Š ëª¨ë‹ˆí„°ë§ í†µê³„ (ìµœê·¼ 100ê±´)
========================================
ì´ ë©”ì‹œì§€ ìˆ˜:   1000 (ì¤‘ë³µ ì œê±° í›„)
ìµœê·¼ ë©”ì‹œì§€:    #6704 (seq)
ë„¤íŠ¸ì›Œí¬ ë ˆì´í„´ì‹œ:  1195.12 Î¼s (avg)
ì²˜ë¦¬ ì‹œê°„:          50.23 Î¼s (avg)
ì´ E2E ë ˆì´í„´ì‹œ:    1245.35 Î¼s (avg)
ì¤‘ë³µ ë©”ì‹œì§€:        0
Queue ì‚¬ìš©ë¥ :       0.5%
========================================
```

---

## 5. ì„±ëŠ¥ ë¶„ì„

### 5.1 ì§€ì—°ì‹œê°„ ë¶„í•´

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   End-to-End Latency                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚                    â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚ Network â”‚         â”‚  Queuing  â”‚       â”‚Processing â”‚
    â”‚ Latency â”‚         â”‚  Latency  â”‚       â”‚  Latency  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      ~1000Î¼s              ~10-100Î¼s           Variable

Network Latency:
  - Publisher send â†’ Subscriber receive
  - Measured: buf->header.recv_time_ns - buf->header.publish_time_ns
  - Typical: ~1000Î¼s (1ms)

Queuing Latency:
  - Subscriber enqueue â†’ Worker dequeue
  - Depends on queue depth and worker processing speed
  - Typical: ~10-100Î¼s (low load)

Processing Latency:
  - Worker dequeue â†’ Business logic complete
  - Depends on business logic complexity
  - Target: < 100Î¼s for simple processing
```

### 5.2 ì„±ëŠ¥ ëª©í‘œ

| êµ¬ì„± ìš”ì†Œ | ëª©í‘œ ì§€ì—°ì‹œê°„ | ëª©í‘œ ì²˜ë¦¬ëŸ‰ |
|-----------|---------------|-------------|
| Subscriber Thread | < 1 Î¼s/msg | > 1M msg/s |
| Buffer Pool Alloc | < 100 ns | - |
| Queue Enqueue | < 50 ns | - |
| Memcpy (4KB) | < 500 ns | - |
| Worker Validation | < 200 ns | - |
| Worker Duplicate Check | < 50 ns | - |
| Worker Business Logic | < 100 Î¼s | > 10K msg/s |
| Monitoring Enqueue | < 50 ns | - |

### 5.3 ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

```
Buffer Pool (1024 buffers Ã— 4KB):  ~4.2 MB
Message Queue (4096 pointers):     ~32 KB
Stats Queue (16384 items):         ~512 KB
Duplicate Set (100K entries):      ~3 MB
Thread Stacks (3 Ã— 8MB):           ~24 MB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:                             ~32 MB
```

### 5.4 CPU ì‚¬ìš©ë¥  ì˜ˆìƒ

```
Low Load (1K msg/s):
  - Subscriber Thread: ~5% (frequent yield)
  - Worker Thread: ~10%
  - Monitoring Thread: ~1%
  - Total: ~16%

Medium Load (100K msg/s):
  - Subscriber Thread: ~50%
  - Worker Thread: ~80%
  - Monitoring Thread: ~5%
  - Total: ~135% (needs 2 cores)

High Load (1M msg/s):
  - Subscriber Thread: ~100% (1 core pinned)
  - Worker Thread: ~100% (1 core pinned)
  - Monitoring Thread: ~10%
  - Total: ~210% (needs 3 cores)

Recommendation:
  - Pin Subscriber to Core 0 (highest priority)
  - Pin Worker to Core 1
  - Monitoring on Core 2 or shared
```

---

## 6. ë°±í”„ë ˆì…”(Backpressure) ì²˜ë¦¬

### 6.1 ì‹œë‚˜ë¦¬ì˜¤ë³„ ëŒ€ì‘

**ì‹œë‚˜ë¦¬ì˜¤ 1: Buffer Pool ê³ ê°ˆ**

```cpp
MessageBuffer* msg_buf = buffer_pool_.allocate();
if (!msg_buf) {
    // Option A: Drop message (ì„±ëŠ¥ ìš°ì„ )
    dropped_count_.fetch_add(1, std::memory_order_relaxed);
    return;

    // Option B: Busy wait (ì‹ ë¢°ì„± ìš°ì„ )
    while (!msg_buf) {
        std::this_thread::yield();
        msg_buf = buffer_pool_.allocate();
    }
}
```

**ê¶Œì¥**: Option A (Drop) + ëª¨ë‹ˆí„°ë§ ì•Œë¦¼

**ì‹œë‚˜ë¦¬ì˜¤ 2: Message Queue ê°€ë“ ì°¸**

```cpp
if (!message_queue_.enqueue(msg_buf)) {
    // Return buffer to pool
    buffer_pool_.deallocate(msg_buf);
    queue_full_count_.fetch_add(1, std::memory_order_relaxed);

    // Optional: Log warning if frequent
    if (queue_full_count_ % 1000 == 0) {
        LOG_WARN("Message queue full, dropped " << queue_full_count_ << " messages");
    }
}
```

**ì‹œë‚˜ë¦¬ì˜¤ 3: Worker Thread ëŠë¦¼**

```
Detection:
  - Queue depth > 50% â†’ Warning
  - Queue depth > 80% â†’ Critical
  - Sustained high depth â†’ Add worker thread

Response:
  - Single worker: Optimize business logic
  - Multiple workers: Add more worker threads (thread pool)
```

### 6.2 ëª¨ë‹ˆí„°ë§ ì§€í‘œ

```cpp
struct SystemMetrics {
    uint64_t messages_received;      // Total Aeron messages
    uint64_t messages_processed;     // Successfully processed
    uint64_t messages_dropped;       // Pool exhausted
    uint64_t messages_queue_full;    // Queue full
    uint64_t messages_duplicates;    // Duplicate detected
    uint64_t messages_invalid;       // Validation failed

    size_t buffer_pool_available;    // Free buffers
    size_t message_queue_depth;      // Current queue size
    size_t stats_queue_depth;        // Stats queue size

    double avg_network_latency_us;
    double avg_processing_latency_us;
    double avg_e2e_latency_us;
};

// Print every 10 seconds
void printSystemMetrics(const SystemMetrics& metrics) {
    std::cout << "=== System Metrics ===" << std::endl;
    std::cout << "Received:    " << metrics.messages_received << std::endl;
    std::cout << "Processed:   " << metrics.messages_processed << std::endl;
    std::cout << "Dropped:     " << metrics.messages_dropped << std::endl;
    std::cout << "Queue Full:  " << metrics.messages_queue_full << std::endl;
    std::cout << "Duplicates:  " << metrics.messages_duplicates << std::endl;
    std::cout << "Invalid:     " << metrics.messages_invalid << std::endl;
    std::cout << "Buffer Pool: " << metrics.buffer_pool_available << " / 1024" << std::endl;
    std::cout << "Msg Queue:   " << metrics.message_queue_depth << " / 4096" << std::endl;
}
```

---

## 7. êµ¬í˜„ ê³„íš

### 7.1 Phase 1: ê¸°ë³¸ êµ¬ì¡° (Buffer Pool + Queue)

**Files to Create**:
1. `subscriber/include/MessageBuffer.h` - Buffer êµ¬ì¡° ì •ì˜
2. `subscriber/include/BufferPool.h` - Lock-free buffer pool
3. `subscriber/include/MessageQueue.h` - Zero-copy queue (í¬ì¸í„° ê¸°ë°˜)

**Files to Modify**:
1. `subscriber/include/AeronSubscriber.h` - Add buffer pool, message queue
2. `subscriber/src/AeronSubscriber.cpp` - Implement fast path

**Estimated Effort**: 4-6 hours

### 7.2 Phase 2: Worker Thread

**Files to Create**:
1. `subscriber/include/MessageWorker.h` - Worker thread class
2. `subscriber/src/MessageWorker.cpp` - Worker implementation

**Files to Modify**:
1. `subscriber/src/main.cpp` - Launch worker thread

**Estimated Effort**: 3-4 hours

### 7.3 Phase 3: ëª¨ë‹ˆí„°ë§ í†µí•©

**Files to Modify**:
1. `subscriber/src/MessageWorker.cpp` - Add monitoring stats
2. `subscriber_monitoring_example.cpp` - Update to new architecture

**Estimated Effort**: 2-3 hours

### 7.4 Phase 4: í…ŒìŠ¤íŠ¸ ë° ìµœì í™”

**Tasks**:
1. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ë ˆì´í„´ì‹œ, ì²˜ë¦¬ëŸ‰)
2. ë°±í”„ë ˆì…” í…ŒìŠ¤íŠ¸ (ê³ ë¶€í•˜)
3. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í™•ì¸ (Valgrind)
4. CPU í”„ë¡œíŒŒì¼ë§ (perf)

**Estimated Effort**: 4-6 hours

**Total**: ~15-20 hours

---

## 8. ëŒ€ì•ˆ ë° íŠ¸ë ˆì´ë“œì˜¤í”„

### 8.1 ëŒ€ì•ˆ 1: Shared Memory IPC (ëŒ€ì‹  Queue)

**ì¥ì **:
- ì§„ì •í•œ zero-copy (ê°™ì€ í”„ë¡œì„¸ìŠ¤ ë‚´)
- Faster than TCP/UDP

**ë‹¨ì **:
- ê°™ì€ í”„ë¡œì„¸ìŠ¤ ë‚´ì—ì„œë§Œ ë™ì‘
- í˜„ì¬ êµ¬ì¡°ì—ì„œ thread ê°„ í†µì‹ ì´ë¯€ë¡œ ë¶ˆí•„ìš”

**ê²°ë¡ **: í˜„ì¬ ì„¤ê³„ ìœ ì§€ (in-process queue)

### 8.2 ëŒ€ì•ˆ 2: Thread Pool (ëŒ€ì‹  Single Worker)

**ì¥ì **:
- ë†’ì€ ì²˜ë¦¬ëŸ‰ (ë³‘ë ¬ ì²˜ë¦¬)
- ë¶€í•˜ ë¶„ì‚°

**ë‹¨ì **:
- ë©”ì‹œì§€ ìˆœì„œ ë³´ì¥ ì–´ë ¤ì›€ (ì¤‘ìš”!)
- ë³µì¡ë„ ì¦ê°€
- ì»¨í…ìŠ¤íŠ¸ ìŠ¤ìœ„ì¹­ ì˜¤ë²„í—¤ë“œ

**ê²°ë¡ **: Phase 1ì—ì„œëŠ” Single Worker, ì„±ëŠ¥ ë¶€ì¡± ì‹œ Thread Pool ê³ ë ¤

### 8.3 ëŒ€ì•ˆ 3: Ring Buffer (ëŒ€ì‹  Queue)

**ì¥ì **:
- LMAX Disruptor ê°™ì€ ê²€ì¦ëœ ì„¤ê³„
- ë§¤ìš° ë†’ì€ ì²˜ë¦¬ëŸ‰

**ë‹¨ì **:
- ë³µì¡í•œ êµ¬í˜„
- í˜„ì¬ SPSC Queueë¡œ ì¶©ë¶„

**ê²°ë¡ **: í˜„ì¬ ì„¤ê³„ ìœ ì§€, í•„ìš” ì‹œ ë‚˜ì¤‘ì— ê³ ë ¤

---

## 9. ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ

### 9.1 í˜¸í™˜ì„± ìœ ì§€

```cpp
// Old API (backward compatibility)
void AeronSubscriber::setMessageCallback(MessageCallback callback) {
    // Store callback for compatibility
    legacy_callback_ = std::move(callback);
}

// New API
void AeronSubscriber::setWorkerCallback(WorkerCallback callback) {
    worker_callback_ = std::move(callback);
}
```

### 9.2 ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜

**Step 1**: ê¸°ì¡´ ì½”ë“œ ìœ ì§€í•˜ë©´ì„œ ìƒˆ êµ¬ì¡° ì¶”ê°€
**Step 2**: ìƒˆ ë¹Œë“œ íƒ€ê²Ÿ ì¶”ê°€ (`aeron_subscriber_zerocopy`)
**Step 3**: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
**Step 4**: ê¸°ì¡´ subscriberë¥¼ ìƒˆ êµ¬ì¡°ë¡œ êµì²´

### 9.3 Rollback ê³„íš

- ê¸°ì¡´ `aeron_subscriber` ë°”ì´ë„ˆë¦¬ ìœ ì§€
- ìƒˆ ë°”ì´ë„ˆë¦¬ëŠ” `aeron_subscriber_v2` ë¡œ ë³„ë„ ìƒì„±
- ë¬¸ì œ ë°œìƒ ì‹œ ê¸°ì¡´ ë°”ì´ë„ˆë¦¬ë¡œ ì¦‰ì‹œ ì „í™˜

---

## 10. ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„

### 10.1 í•µì‹¬ ì„¤ê³„ ê²°ì •

1. **Thread ë¶„ë¦¬**: Subscriber (ìˆ˜ì‹ ) + Worker (ì²˜ë¦¬) + Monitoring
2. **Zero-copy**: Buffer pool + Pointer queue
3. **Lock-free**: ëª¨ë“  íì™€ í’€ì€ lock-free
4. **ëª¨ë‹ˆí„°ë§**: Worker threadì—ì„œ í†µí•© (ì˜µì…˜ A)
5. **ë°±í”„ë ˆì…”**: Drop message + ëª¨ë‹ˆí„°ë§ ì•Œë¦¼

### 10.2 ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ 

| ì§€í‘œ | í˜„ì¬ | ì˜ˆìƒ | ê°œì„  |
|------|------|------|------|
| Subscriber ì‘ë‹µì„± | ~337ns + processing | < 1Î¼s | ì¼ì • |
| ì²˜ë¦¬ëŸ‰ (theoretical) | ~100K msg/s | > 1M msg/s | 10x |
| ë©”ì‹œì§€ ì†ì‹¤ (ê³ ë¶€í•˜) | ë†’ìŒ (blocking) | ë‚®ìŒ (queue) | ê°œì„  |
| ë ˆì´í„´ì‹œ ë³€ë™ì„± | ë†’ìŒ | ë‚®ìŒ | ê°œì„  |

### 10.3 ë‹¤ìŒ ë‹¨ê³„

1. **ì„¤ê³„ ê²€í† ** - ì‚¬ìš©ì ìŠ¹ì¸
2. **Phase 1 êµ¬í˜„** - Buffer pool + Queue
3. **Phase 2 êµ¬í˜„** - Worker thread
4. **Phase 3 êµ¬í˜„** - ëª¨ë‹ˆí„°ë§ í†µí•©
5. **Phase 4 í…ŒìŠ¤íŠ¸** - ì„±ëŠ¥ ê²€ì¦

---

**ë¬¸ì„œ ì‘ì„± ì™„ë£Œ** - êµ¬í˜„ ìŠ¹ì¸ ëŒ€ê¸° ì¤‘
